{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MgEL76crb6r"
      },
      "outputs": [],
      "source": [
        "# Single Object Detection in an Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Read the ImageNet class names from a file\n",
        "with open('classification_classes_ILSVRC2012.txt', 'r') as f:\n",
        "    image_net_names = f.read().split('\\n')\n",
        "# Extract the first word of each class name from ImageNet\n",
        "classes = [name.split(',')[0] for name in image_net_names]\n",
        "\n",
        "# Load the pre-trained neural network model\n",
        "model = cv2.dnn.readNet(model='DenseNet_121.caffemodel',\n",
        "                      config='DenseNet_121.prototxt',\n",
        "                      framework='Caffe')\n",
        "\n",
        "# Load the image from the disk\n",
        "image = cv2.imread('image_1.jpg')\n",
        "# Convert the image to a blob format required by the model\n",
        "blob = cv2.dnn.blobFromImage(image=image, scalefactor=0.01, size=(224, 224),\n",
        "                             mean=(104, 117, 123))\n",
        "# Set the blob as input to the neural network\n",
        "model.setInput(blob)\n",
        "# Perform a forward pass through the neural network\n",
        "outputs = model.forward()\n",
        "\n",
        "final = outputs[0]\n",
        "# Flatten the output to a 1D array\n",
        "final = final.reshape(1000, 1)\n",
        "# Determine the class label with the highest score\n",
        "idlabel = np.argmax(final)\n",
        "# Convert scores to probabilities using softmax\n",
        "probability = np.exp(final) / np.sum(np.exp(final))\n",
        "# Extract the highest probability\n",
        "final_prob = np.max(probability) * 100.\n",
        "# Map the highest probability to the corresponding class name\n",
        "out = classes[idlabel]\n",
        "text = f\"{out}, {final_prob:.3f}\"\n",
        "\n",
        "# Annotate the image with the class name and probability\n",
        "cv2.putText(image, text, (25, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
        "\n",
        "# Display the image with annotation\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)\n",
        "# Save the annotated image to disk\n",
        "cv2.imwrite('outputs/result_image.jpg', image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSYQMv9Y4tp_"
      },
      "outputs": [],
      "source": [
        "# Multi-Object Detection in an Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load COCO class labels\n",
        "with open('/content/object_detection_classes_coco.txt', 'r') as file:\n",
        "    class_labels = file.read().split('\\n')\n",
        "\n",
        "# Generate a unique color for each class\n",
        "colors = np.random.uniform(0, 255, size=(len(class_labels), 3))\n",
        "\n",
        "# Load the pre-trained DNN model\n",
        "dnn_model = cv2.dnn.readNet(model='/content/frozen_inference_graph.pb',\n",
        "                            config='ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt',\n",
        "                            framework='TensorFlow')\n",
        "\n",
        "# Load the image from disk\n",
        "input_image = cv2.imread('image_2.jpg')  # tiger image\n",
        "image_height, image_width, _ = input_image.shape\n",
        "\n",
        "# Convert the image to a blob format\n",
        "image_blob = cv2.dnn.blobFromImage(image=input_image, size=(300, 300), mean=(104, 117, 123), swapRB=True)\n",
        "\n",
        "# Set the blob as input to the model\n",
        "dnn_model.setInput(image_blob)\n",
        "\n",
        "# Perform forward pass to get detections\n",
        "detections = dnn_model.forward()\n",
        "\n",
        "# Iterate over the detections\n",
        "for detection in detections[0, 0, :, :]:\n",
        "    # Extract the confidence level of the detection\n",
        "    detection_confidence = detection[2]\n",
        "\n",
        "    # Draw bounding boxes for detections above the confidence threshold\n",
        "    if detection_confidence > 0.4:\n",
        "        # Get the class ID\n",
        "        class_id = detection[1]\n",
        "        # Map class ID to class label\n",
        "        class_label = class_labels[int(class_id) - 1]\n",
        "        color = colors[int(class_id)]\n",
        "        # Calculate bounding box coordinates\n",
        "        x_start = detection[3] * image_width\n",
        "        y_start = detection[4] * image_height\n",
        "        x_end = detection[5] * image_width\n",
        "        y_end = detection[6] * image_height\n",
        "        # Draw the bounding box\n",
        "        cv2.rectangle(input_image, (int(x_start), int(y_start)), (int(x_end), int(y_end)), color, thickness=2)\n",
        "        # Prepare label with class name and confidence\n",
        "        label_text = f\"{class_label}, {detection_confidence * 100:.3f}\"\n",
        "        # Put label text on the image\n",
        "        cv2.putText(input_image, label_text, (int(x_start), int(y_start - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "# Show the image with detected objects\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "# Save the image with bounding boxes and labels\n",
        "cv2.imwrite('image_result.jpg', input_image)\n",
        "\n",
        "# Wait for a key press and close all windows\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A66kpRHruEWt"
      },
      "outputs": [],
      "source": [
        "# Video Object Detection\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load COCO class labels\n",
        "with open('object_detection_classes_coco.txt', 'r') as file:\n",
        "    class_labels = file.read().split('\\n')\n",
        "\n",
        "# Generate unique colors for each class\n",
        "colors = np.random.uniform(0, 255, size=(len(class_labels), 3))\n",
        "\n",
        "# Load the pre-trained DNN model\n",
        "dnn_model = cv2.dnn.readNet(model='frozen_inference_graph.pb',\n",
        "                            config='ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt',\n",
        "                            framework='TensorFlow')\n",
        "\n",
        "# Capture video from file\n",
        "video_capture = cv2.VideoCapture('video_1.mp4')\n",
        "# Get video dimensions for proper saving\n",
        "frame_width = int(video_capture.get(3))\n",
        "frame_height = int(video_capture.get(4))\n",
        "# Create a VideoWriter object to save the output video\n",
        "video_writer = cv2.VideoWriter('video_result.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30,\n",
        "                               (frame_width, frame_height))\n",
        "\n",
        "# Process each frame of the video\n",
        "while video_capture.isOpened():\n",
        "    ret, frame = video_capture.read()\n",
        "    if ret:\n",
        "        input_frame = frame\n",
        "        frame_height, frame_width, _ = input_frame.shape\n",
        "        # Convert the frame to a blob format\n",
        "        frame_blob = cv2.dnn.blobFromImage(image=input_frame, size=(300, 300), mean=(104, 117, 123),\n",
        "                                           swapRB=True)\n",
        "        # Start timing for FPS calculation\n",
        "        start_time = time.time()\n",
        "        dnn_model.setInput(frame_blob)\n",
        "        detections = dnn_model.forward()\n",
        "        # End timing after detection\n",
        "        end_time = time.time()\n",
        "        # Calculate FPS for the current frame\n",
        "        fps = 1 / (end_time - start_time)\n",
        "        # Iterate over the detections\n",
        "        for detection in detections[0, 0, :, :]:\n",
        "            # Extract the confidence level of the detection\n",
        "            detection_confidence = detection[2]\n",
        "            # Draw bounding boxes for detections above the confidence threshold\n",
        "            if detection_confidence > 0.4:\n",
        "                # Get the class ID\n",
        "                class_id = detection[1]\n",
        "                # Map class ID to class label\n",
        "                class_label = class_labels[int(class_id) - 1]\n",
        "                color = colors[int(class_id)]\n",
        "                # Calculate bounding box coordinates\n",
        "                x_start = detection[3] * frame_width\n",
        "                y_start = detection[4] * frame_height\n",
        "                x_end = detection[5] * frame_width\n",
        "                y_end = detection[6] * frame_height\n",
        "                # Draw the bounding box\n",
        "                cv2.rectangle(input_frame, (int(x_start), int(y_start)), (int(x_end), int(y_end)), color, thickness=2)\n",
        "                # Put class label text on the detected object\n",
        "                cv2.putText(input_frame, class_label, (int(x_start), int(y_start - 5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "                # Put FPS text on the top of the frame\n",
        "                cv2.putText(input_frame, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        cv2_imshow(input_frame)\n",
        "        video_writer.write(input_frame)\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}